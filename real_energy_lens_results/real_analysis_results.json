{
  "config": {
    "model_name": "gpt2",
    "sae_dict_size": 512,
    "energy_layers": [
      6,
      8,
      10
    ],
    "max_seq_len": 32,
    "device": "cpu"
  },
  "model_info": {
    "name": "gpt2",
    "n_layers": 12,
    "n_embd": 768,
    "vocab_size": 50257
  },
  "samples": {
    "regex_pattern": {
      "text": "The regex \\d+ matches numbers in text strings effectively.",
      "tokens": [
        "The",
        "\u0120regex",
        "\u0120\\",
        "d",
        "+",
        "\u0120matches",
        "\u0120numbers",
        "\u0120in",
        "\u0120text",
        "\u0120strings",
        "\u0120effectively",
        "."
      ],
      "energy_traces": {
        "6": [
          23.025850296020508,
          23.025850296020508,
          6.392365455627441,
          8.248244285583496,
          22.970985412597656,
          23.025850296020508,
          2.564436674118042,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          7.652486801147461,
          7.652486801147461
        ],
        "8": [
          23.025850296020508,
          23.025850296020508,
          10.59182357788086,
          0.22023779153823853,
          23.025850296020508,
          23.025850296020508,
          2.766422986984253,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          7.668559551239014,
          7.668559551239014
        ],
        "10": [
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          14.030513763427734,
          23.025850296020508,
          23.025850296020508,
          5.869119167327881,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          4.7970380783081055,
          4.7970380783081055
        ]
      },
      "energy_stats": {
        "6": {
          "mean": 16.136342267195385,
          "std": 8.250351884603363,
          "min": 2.564436674118042,
          "max": 23.025850296020508
        },
        "8": {
          "mean": 15.841379627585411,
          "std": 8.838545834555141,
          "min": 0.22023779153823853,
          "max": 23.025850296020508
        },
        "10": {
          "mean": 17.80837595462799,
          "std": 7.709216508272307,
          "min": 4.7970380783081055,
          "max": 23.025850296020508
        }
      }
    },
    "code_snippet": {
      "text": "def parse_data(x): return x.strip().split(',') if x else []",
      "tokens": [
        "def",
        "\u0120parse",
        "_",
        "data",
        "(",
        "x",
        "):",
        "\u0120return",
        "\u0120x",
        ".",
        "strip",
        "().",
        "split",
        "(",
        "',",
        "')",
        "\u0120if",
        "\u0120x",
        "\u0120else",
        "\u0120[]"
      ],
      "energy_traces": {
        "6": [
          23.025850296020508,
          15.652536392211914,
          19.449317932128906,
          21.357345581054688,
          16.811426162719727,
          23.025850296020508,
          20.38472557067871,
          22.95010757446289,
          1.8022202253341675,
          23.025850296020508,
          23.025497436523438,
          23.025840759277344,
          7.005741596221924,
          23.02578353881836,
          22.88513946533203,
          12.34814167022705,
          23.024446487426758,
          23.025850296020508,
          22.969573974609375,
          22.969573974609375
        ],
        "8": [
          23.025850296020508,
          18.019224166870117,
          23.025850296020508,
          22.994905471801758,
          17.007766723632812,
          23.025850296020508,
          14.41828441619873,
          20.84720802307129,
          0.6957404613494873,
          23.025850296020508,
          23.025846481323242,
          23.02581787109375,
          6.8094964027404785,
          23.025850296020508,
          23.025850296020508,
          18.613374710083008,
          22.137245178222656,
          23.025850296020508,
          21.76892852783203,
          21.76892852783203
        ],
        "10": [
          23.025850296020508,
          23.01198959350586,
          23.025850296020508,
          23.02581214904785,
          23.025850296020508,
          23.025850296020508,
          23.01926040649414,
          22.99867820739746,
          0.09029065072536469,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          -0.0,
          23.025850296020508,
          23.025850296020508,
          19.408281326293945,
          21.85468864440918,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508
        ]
      },
      "energy_stats": {
        "6": {
          "mean": 19.539540976285934,
          "std": 5.888889936134625,
          "min": 1.8022202253341675,
          "max": 23.025850296020508
        },
        "8": {
          "mean": 19.615685951709747,
          "std": 5.884556276493851,
          "min": 0.6957404613494873,
          "max": 23.025850296020508
        },
        "10": {
          "mean": 20.485960226505995,
          "std": 6.861735369160549,
          "min": -0.0,
          "max": 23.025850296020508
        }
      }
    },
    "natural_language": {
      "text": "The quick brown fox jumps over the lazy sleeping dog.",
      "tokens": [
        "The",
        "\u0120quick",
        "\u0120brown",
        "\u0120fox",
        "\u0120jumps",
        "\u0120over",
        "\u0120the",
        "\u0120lazy",
        "\u0120sleeping",
        "\u0120dog",
        "."
      ],
      "energy_traces": {
        "6": [
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          13.127640724182129,
          0.00036305817775428295,
          23.021169662475586,
          23.025850296020508,
          23.02577018737793,
          4.62145471572876,
          4.62145471572876
        ],
        "8": [
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          15.254955291748047,
          4.768372718899627e-07,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          4.235772132873535,
          4.235772132873535
        ],
        "10": [
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.02530860900879,
          -0.0,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          10.877176284790039,
          10.877176284790039
        ]
      },
      "energy_stats": {
        "6": {
          "mean": 16.686100413070314,
          "std": 8.859891627556626,
          "min": 0.00036305817775428295,
          "max": 23.025850296020508
        },
        "8": {
          "mean": 16.809768373315993,
          "std": 8.901859992821931,
          "min": 4.768372718899627e-07,
          "max": 23.025850296020508
        },
        "10": {
          "mean": 18.72369211370295,
          "std": 7.518317796180233,
          "min": -0.0,
          "max": 23.025850296020508
        }
      }
    },
    "mathematical": {
      "text": "The derivative of x squared equals two times x by power rule.",
      "tokens": [
        "The",
        "\u0120derivative",
        "\u0120of",
        "\u0120x",
        "\u0120squared",
        "\u0120equals",
        "\u0120two",
        "\u0120times",
        "\u0120x",
        "\u0120by",
        "\u0120power",
        "\u0120rule",
        "."
      ],
      "energy_traces": {
        "6": [
          23.025850296020508,
          4.563790798187256,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          17.709794998168945,
          18.480621337890625,
          17.165206909179688,
          23.025028228759766,
          23.025686264038086,
          23.025850296020508,
          0.44441330432891846,
          0.44441330432891846
        ],
        "8": [
          23.025850296020508,
          11.72861099243164,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025836944580078,
          23.025819778442383,
          23.02029800415039,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          1.0812010765075684,
          1.0812010765075684
        ],
        "10": [
          23.025850296020508,
          18.473459243774414,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          0.052811868488788605,
          0.052811868488788605
        ]
      },
      "energy_stats": {
        "6": {
          "mean": 16.922169740383442,
          "std": 8.59178056997887,
          "min": 0.44441330432891846,
          "max": 23.025850296020508
        },
        "8": {
          "mean": 18.78030153421255,
          "std": 8.116659078193107,
          "min": 1.0812010765075684,
          "max": 23.025850296020508
        },
        "10": {
          "mean": 19.141352764689007,
          "std": 8.22792655232682,
          "min": 0.052811868488788605,
          "max": 23.025850296020508
        }
      }
    },
    "technical_text": {
      "text": "Neural networks use backpropagation to optimize loss functions.",
      "tokens": [
        "Ne",
        "ural",
        "\u0120networks",
        "\u0120use",
        "\u0120back",
        "prop",
        "ag",
        "ation",
        "\u0120to",
        "\u0120optimize",
        "\u0120loss",
        "\u0120functions",
        "."
      ],
      "energy_traces": {
        "6": [
          23.025850296020508,
          22.887208938598633,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          11.54345703125,
          21.870731353759766,
          14.136306762695312,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          1.417420744895935,
          1.417420744895935
        ],
        "8": [
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          15.098997116088867,
          22.986745834350586,
          19.33264923095703,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          0.8924230933189392,
          0.8924230933189392
        ],
        "10": [
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          5.339393138885498,
          2.2141804695129395,
          23.025850296020508,
          23.025850296020508,
          23.025850296020508,
          0.02116534113883972,
          0.02116534113883972
        ]
      },
      "energy_stats": {
        "6": {
          "mean": 18.034884434479935,
          "std": 7.95296119424172,
          "min": 1.417420744895935,
          "max": 23.025850296020508
        },
        "8": {
          "mean": 18.72384928739988,
          "std": 7.921051305809352,
          "min": 0.8924230933189392,
          "max": 23.025850296020508
        },
        "10": {
          "mean": 16.52527361191236,
          "std": 9.825476944962402,
          "min": 0.02116534113883972,
          "max": 23.025850296020508
        }
      }
    }
  },
  "sae_analysis": {
    "layer": 8,
    "n_samples": 69,
    "dict_size": 512,
    "reconstruction_error": 834.5640855984368,
    "sparsity": 8.0
  },
  "behavioral_validation": {
    "next_token_prediction": {
      "text_0": {
        "text": "The regex \\d+ matches numbers in text strings effectively.",
        "perplexity": 362.72564697265625,
        "avg_confidence": 0.2100752741098404,
        "avg_entropy": 4.822052001953125,
        "loss": 5.893646717071533
      },
      "text_1": {
        "text": "def parse_data(x): return x.strip().split(',') if x else []",
        "perplexity": 32.05961990356445,
        "avg_confidence": 0.21999359130859375,
        "avg_entropy": 4.436587810516357,
        "loss": 3.467597246170044
      },
      "text_2": {
        "text": "The quick brown fox jumps over the lazy sleeping dog.",
        "perplexity": 205.4999237060547,
        "avg_confidence": 0.18645809590816498,
        "avg_entropy": 5.325118064880371,
        "loss": 5.325445652008057
      },
      "text_3": {
        "text": "The derivative of x squared equals two times x by power rule.",
        "perplexity": 442.1632080078125,
        "avg_confidence": 0.24799233675003052,
        "avg_entropy": 4.921180248260498,
        "loss": 6.091679096221924
      },
      "text_4": {
        "text": "Neural networks use backpropagation to optimize loss functions.",
        "perplexity": 55.30865478515625,
        "avg_confidence": 0.3344595730304718,
        "avg_entropy": 4.248056888580322,
        "loss": 4.012929439544678
      }
    },
    "perplexity_analysis": {},
    "feature_intervention": {
      "top_feature_id": 182,
      "efas_score": -0.3826572484561496,
      "p_value": 0.24,
      "behavioral_impact": -0.04843810519070619,
      "attractor_shift": 0.16852686055727895
    }
  },
  "statistical_summary": {
    "n_alignments": 5,
    "efas_distribution": {
      "mean": 0.2531742166665164,
      "std": 0.08905183364541464,
      "max": 0.3826572484561496,
      "min": 0.10710231311099429
    },
    "significance": {
      "n_significant": 0,
      "mean_p_value": 0.45999999999999996,
      "min_p_value": 0.24
    },
    "behavioral_impact": {
      "mean": -0.010655165591608689,
      "max": 0.10792020398004204
    }
  },
  "top_alignments": [
    {
      "layer": 8,
      "feature_id": 182,
      "efas_score": -0.3826572484561496,
      "p_value": 0.24,
      "behavioral_impact": -0.04843810519070619,
      "attractor_shift": 0.16852686055727895
    },
    {
      "layer": 8,
      "feature_id": 319,
      "efas_score": 0.27539569134163283,
      "p_value": 0.43,
      "behavioral_impact": 0.10792020398004204,
      "attractor_shift": 0.15834500625295034
    },
    {
      "layer": 8,
      "feature_id": 278,
      "efas_score": -0.273146418933963,
      "p_value": 0.44,
      "behavioral_impact": -0.03953793969079328,
      "attractor_shift": 0.1373334872389273
    },
    {
      "layer": 8,
      "feature_id": 313,
      "efas_score": -0.22756941148984208,
      "p_value": 0.42,
      "behavioral_impact": -0.0359521706968071,
      "attractor_shift": 0.12532467785742843
    },
    {
      "layer": 8,
      "feature_id": 152,
      "efas_score": -0.10710231311099429,
      "p_value": 0.77,
      "behavioral_impact": -0.03726781635977892,
      "attractor_shift": 0.06373096032912566
    }
  ]
}